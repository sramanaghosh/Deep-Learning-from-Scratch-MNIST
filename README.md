# Deep-Learning-from-Scratch-MNIST
# Neural Network Fundamentals: MNIST from Scratch

This project is a complete implementation of a deep learning library built using only **NumPy**. It was developed to explore the mathematical foundations of neural networks, including backpropagation, gradient descent, and numerical stability.

## ðŸš€ Key Features
* **From-Scratch Implementation**: No deep learning frameworks (like PyTorch or TensorFlow) were used.
* **Modular Architecture**: Includes customizable layers (Dense), activation functions (ReLU, Sigmoid, Softmax), and loss functions (MSE, Cross-Entropy).
* **Gradient Checking**: Includes a robust numerical verification system to ensure backpropagation accuracy with a relative error threshold of < 1e-5.

## ðŸ› ï¸ Tech Stack
* **Language**: Python 3.x
* **Libraries**: NumPy, Matplotlib.

## âš¡ How to Run
```bash
python 700782611_pa1.py
